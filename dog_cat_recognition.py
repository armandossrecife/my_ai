# -*- coding: utf-8 -*-
"""dog_cat_ recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/165izd47UmVrP1sBLyYoyadjMempOkJaw

# Step 1: Setup and Installation
"""

!pip install torch torchvision pillow matplotlib

!nvidia-smi

"""# Step 2: Import Required Libraries"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from PIL import Image
import os
import matplotlib.pyplot as plt
import numpy as np

"""# Step 3: Prepare the Dataset"""

class CatDogDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        # Only include common image file extensions
        self.images = [f for f in os.listdir(root_dir)
                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]

        if not self.images:
            raise RuntimeError(f"No valid images found in {root_dir}")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        img_path = os.path.join(self.root_dir, img_name)

        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            # Return a random valid image instead
            return self.__getitem__(torch.randint(0, len(self)-1, (1,)).item())

        # Convert filename to label (0 for cat, 1 for dog)
        label = 0 if 'cat' in img_name.lower() else 1

        if self.transform:
            image = self.transform(image)

        return image, label

"""# Step 4: Define Data Transforms and Loaders"""

!curl -i https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip

import os
import urllib.request
import tarfile
import logging
import zipfile

# URL for a small sample of the cats vs dogs dataset
URL = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'
DATA_DIR = 'data'

def download_and_extract(url, data_dir):
    """
    Downloads and extracts the dataset from the given URL to the specified directory.
    Handles errors gracefully and logs progress.

    Args:
        url (str): The URL of the dataset (e.g., a zip or tar.gz file).
        data_dir (str): The directory where the data should be downloaded and extracted.
    """
    # Setup logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    try:
        # Create data directory if it doesn't exist
        os.makedirs(data_dir, exist_ok=True)
        logging.info(f"Created data directory: {data_dir}")

        # Download the file
        filename = os.path.basename(url)  # Get filename from URL
        filepath = os.path.join(data_dir, filename)
        if not os.path.exists(filepath):
            logging.info(f"Downloading {filename} from {url} to {filepath}")
            try:
                urllib.request.urlretrieve(url, filepath)
                logging.info(f"Download of {filename} complete.")
            except Exception as e:
                logging.error(f"Error downloading {filename}: {e}")
                raise  # Re-raise the exception to be caught by the outer try-except

        else:
            logging.info(f"{filename} already exists at {filepath}. Skipping download.")

        # Extract the file (check file type to use the correct extraction method)
        if filepath.endswith('.zip'):
            logging.info(f"Extracting {filepath}...")
            try:
                with zipfile.ZipFile(filepath, 'r') as zip_ref:
                    zip_ref.extractall(data_dir)
                logging.info(f"Extraction of {filepath} complete.")
            except Exception as e:
                logging.error(f"Error extracting {filepath}: {e}")
                raise
        elif filepath.endswith(('.tar', '.tar.gz', '.tgz')):
            logging.info(f"Extracting {filepath}...")
            try:
                with tarfile.open(filepath, 'r*') as tar_ref:  # Use 'r*' for auto detection
                    tar_ref.extractall(path=data_dir)
                logging.info(f"Extraction of {filepath} complete.")
            except Exception as e:
                logging.error(f"Error extracting {filepath}: {e}")
                raise
        else:
            logging.warning(f"Don't know how to extract {filename}. Skipping extraction.")

        # Create train/val directories (outside the extraction)
        os.makedirs(os.path.join(data_dir, 'train'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, 'val'), exist_ok=True)
        logging.info("Created train and val directories.")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        # Optionally, re-raise the exception if you want the calling code to handle it
        raise

import os

# Print current working directory
print("Current working directory:", os.getcwd())

# Check if data/train exists
print("Does data/train exist?", os.path.exists('data/train'))

# List contents of data directory if it exists
if os.path.exists('data'):
    print("Contents of data directory:", os.listdir('data'))

import random
import shutil

def copy_random_files(source_folder, dest_folder, num_files, pre_name):
    """
    Copies a specified number of files randomly from a source folder to a destination folder.

    Args:
        source_folder (str): Path to the folder containing the files to copy.
        dest_folder (str): Path to the folder where the files will be copied.
        num_files (int): The number of files to copy.
    """
    try:
        # Get a list of all files in the source folder
        files = [f for f in os.listdir(source_folder) if os.path.isfile(os.path.join(source_folder, f))]
        # files = glob.glob(os.path.join(source_folder, '*')) # Alternative

        if not files:
            print(f"Error: No files found in the source folder: {source_folder}")
            return

        # Check if the number of files to copy exceeds the number of available files
        if num_files > len(files):
            print(f"Error: Number of files to copy ({num_files}) exceeds the number of files in the source folder ({len(files)}).  Copying all available files.")
            num_files = len(files) #Correct num_files

        # Create the destination folder if it doesn't exist
        os.makedirs(dest_folder, exist_ok=True)

        # Randomly select files to copy
        files_to_copy = random.sample(files, num_files)

        # Copy the files
        for file_name in files_to_copy:
            source_path = os.path.join(source_folder, file_name)
            new_file_name = pre_name + "." + file_name
            dest_path = os.path.join(dest_folder, new_file_name)
            try:
                shutil.copy2(source_path, dest_path)  # Use copy2 to preserve metadata
                print(f"Copied: {file_name} to {new_file_name} in {dest_path}")
            except Exception as e:
                print(f"Error copying {file_name}: {e}")

        print(f"Successfully copied {num_files} files from {source_folder} to {dest_folder}")

    except Exception as e:
        print(f"An error occurred: {e}")

download_and_extract(URL, DATA_DIR)

!find /content/data/PetImages/Cat -type f | wc -l

!find /content/data/PetImages/Dog -type f | wc -l

!ls -l /content/data/train

!ls -l /content/data/val

source_folder_train_cat = "/content/data/PetImages/Cat"  # Replace with the actual source folder path
dest_folder_train_cat = "/content/data/train"  # Replace with the actual destination folder path
num_files_to_copy = 1000  # Change this to the desired number of files to copy
copy_random_files(source_folder_train_cat, dest_folder_train_cat, num_files_to_copy, "cat")

source_folder_train_dog = "/content/data/PetImages/Dog"  # Replace with the actual source folder path
dest_folder_train_dog = "/content/data/train"  # Replace with the actual destination folder path
num_files_to_copy = 1000  # Change this to the desired number of files to copy
copy_random_files(source_folder_train_dog, dest_folder_train_dog, num_files_to_copy, "dog")

source_folder_val_cat = "/content/data/PetImages/Cat"  # Replace with the actual source folder path
dest_folder_val_cat = "/content/data/val"  # Replace with the actual destination folder path
num_files_to_copy = 1000  # Change this to the desired number of files to copy
copy_random_files(source_folder_val_cat, dest_folder_val_cat, num_files_to_copy, "cat")

source_folder_val_dog = "/content/data/PetImages/Dog"  # Replace with the actual source folder path
dest_folder_val_dog = "/content/data/val"  # Replace with the actual destination folder path
num_files_to_copy = 1000  # Change this to the desired number of files to copy
copy_random_files(source_folder_val_dog, dest_folder_val_dog, num_files_to_copy, "dog")

!find /content/data/train -type f | wc -l

!find /content/data/val -type f | wc -l

# Define transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize to common size
    transforms.ToTensor(),          # Convert to tensor
    transforms.Normalize(           # Normalize
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# Create datasets
train_dataset = CatDogDataset('data/train', transform=transform)
val_dataset = CatDogDataset('data/val', transform=transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

"""# Step 5: Define the Model"""

class CatDogClassifier(nn.Module):
    def __init__(self):
        super(CatDogClassifier, self).__init__()
        # Use a pretrained ResNet model
        self.resnet = models.resnet18(pretrained=True)

        # Freeze all layers except the final one
        for param in self.resnet.parameters():
            param.requires_grad = False

        # Replace the final layer for binary classification
        num_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(num_features, 1)

    def forward(self, x):
        return torch.sigmoid(self.resnet(x))

"""# Step 6: Training Setup"""

# Initialize model, loss function, and optimizer
model = CatDogClassifier()

criterion = nn.BCELoss()  # Binary Cross Entropy Loss
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Check if GPU is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)# Step 6: Training Setup

"""# Step 7: Training Loop"""

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    train_losses = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.float().unsqueeze(1).to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward pass and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)

        # Calculate training loss
        epoch_loss = running_loss / len(train_loader.dataset)
        train_losses.append(epoch_loss)

        # Validation phase
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                labels = labels.float().unsqueeze(1).to(device)

                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)

                predicted = (outputs > 0.5).float()
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_loss = val_loss / len(val_loader.dataset)
        val_losses.append(val_loss)
        accuracy = 100 * correct / total
        val_accuracies.append(accuracy)

        print(f'Epoch {epoch+1}/{num_epochs}, '
              f'Train Loss: {epoch_loss:.4f}, '
              f'Val Loss: {val_loss:.4f}, '
              f'Val Acc: {accuracy:.2f}%')

    return train_losses, val_losses, val_accuracies

print(f"Aguarde...  ")
print("")
# Train the model
train_losses, val_losses, val_accuracies = train_model(
    model, train_loader, val_loader, criterion, optimizer, num_epochs=10
)
print("ConcluÃ­do!")

"""# Step 8: Save the Model"""

torch.save(model.state_dict(), 'cat_dog_classifier.pth')

"""# Step 9: Prediction Function"""

def predict_image(image_path, model, transform, device):
    # Load and transform the image
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)

    # Make prediction
    model.eval()
    with torch.no_grad():
        output = model(image)
        probability = output.item()
        prediction = 'dog' if probability > 0.5 else 'cat'

    return prediction, probability

# Example usage
image_path = 'data/PetImages/Dog/1.jpg'
prediction, probability = predict_image(image_path, model, transform, device)
print(f'Prediction: {prediction} with probability: {probability:.2f}')

# Example usage
image_path_cat = 'data/PetImages/Cat/10005.jpg'
prediction, probability = predict_image(image_path_cat, model, transform, device)
print(f'Prediction: {prediction} with probability: {probability:.2f}')

"""# Step 10: Visualization (Optional)"""

def visualize_predictions(image_paths, model, transform, device):
    plt.figure(figsize=(15, 10))
    for i, image_path in enumerate(image_paths):
        image = Image.open(image_path).convert('RGB')
        prediction, probability = predict_image(image_path, model, transform, device)

        plt.subplot(2, 3, i+1)
        plt.imshow(image)
        plt.title(f'{prediction} ({probability:.2f})')
        plt.axis('off')
    plt.show()

# Example usage
test_images = ['data/PetImages/Dog/1.jpg', 'data/PetImages/Dog/10.jpg', 'data/PetImages/Dog/100.jpg']
visualize_predictions(test_images, model, transform, device)

# Example usage
test_images_cats = ['data/PetImages/Cat/1000.jpg', 'data/PetImages/Cat/10001.jpg', 'data/PetImages/Cat/1002.jpg']
visualize_predictions(test_images_cats, model, transform, device)